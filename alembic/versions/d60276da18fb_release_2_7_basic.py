"""release 2.7 basic

Revision ID: d60276da18fb
Revises: 9c01a3eea1b9
Create Date: 2024-07-22 13:52:03.053682

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from sqlalchemy.schema import CreateTable, DropTable
from sqlalchemy.ext.compiler import compiles
import re


@compiles(CreateTable)
def _add_if_not_exists(element, compiler, **kw):
    output = compiler.visit_create_table(element, **kw)
    if element.element.info.get("ifexists"):
        output = re.sub(
            "^\s*CREATE TABLE", "CREATE TABLE IF NOT EXISTS", output, re.S)
    return output


@compiles(DropTable)
def _add_if_exists(element, compiler, **kw):
    output = compiler.visit_drop_table(element, **kw)
    if element.element.info.get("ifexists"):
        output = re.sub(
            "^\s*DROP TABLE", "DROP TABLE IF EXISTS", output, re.S)
    return output



# revision identifiers, used by Alembic.
revision: str = 'd60276da18fb'
down_revision: Union[str, None] = '9c01a3eea1b9'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('langchain_pg_document',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('collection_id', sa.UUID(), nullable=True),
    sa.Column('jmeta', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('document_summary', sa.String(), nullable=False),
    sa.Column('lang', sa.String(), nullable=False),
    sa.Column('author', sa.String(), nullable=True),
    sa.Column('keyword', postgresql.ARRAY(sa.String()), nullable=True),
    sa.Column('title', sa.String(), nullable=True),
    sa.Column('edition', sa.String(), nullable=True),
    sa.Column('year', sa.String(), nullable=True),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('format', sa.String(), nullable=False),
    sa.Column('original_format', sa.String(), nullable=False),
    sa.Column('processing_time', sa.String(), nullable=False),
    sa.Column('encrypted', sa.String(), nullable=True),
    sa.ForeignKeyConstraint(['collection_id'], ['langchain_pg_collection.uuid'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    info={"ifexists": True}
    )

    op.create_table('langchain_pg_web',
    sa.Column('collection_id', sa.UUID(), nullable=True),
    sa.Column('doc_url', sa.String(), nullable=False),
    sa.Column('timestamp', sa.String(), nullable=False),
    sa.Column('document', sa.String(), nullable=False),
    sa.Column('cmetadata', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('ts_col', postgresql.TSVECTOR(), nullable=True),
    sa.Column('chunk_no', sa.Integer(), nullable=True),
    sa.Column('uuid', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['collection_id'], ['langchain_pg_collection.uuid'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('uuid'),
    info={"ifexists": True}
    )
    op.execute("""ALTER TABLE public.langchain_pg_document ADD COLUMN IF NOT EXISTS encrypted varchar;""")
    op.alter_column('langchain_pg_collection', 'name',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.add_column('langchain_pg_embedding', sa.Column('page', sa.String(), nullable=True))
    op.add_column('langchain_pg_embedding', sa.Column('chunk_num', sa.Integer(), nullable=True))
    op.add_column('langchain_pg_embedding', sa.Column('chunk_len_in_chars', sa.Integer(), nullable=True))
    op.add_column('langchain_pg_embedding', sa.Column('jmeta', postgresql.JSON(astext_type=sa.Text()), nullable=True))
    op.alter_column('langchain_pg_embedding', 'doc_id',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('langchain_pg_embedding', 'document',
               existing_type=sa.VARCHAR(),
               nullable=False)
    # op.drop_constraint('langchain_pg_embedding_collection_id_fkey', 'langchain_pg_embedding', type_='foreignkey')
    # op.create_foreign_key('langchain_pg_embedding_doc_id_fkey', 'langchain_pg_embedding', 'langchain_pg_document', ['doc_id'], ['id'], ondelete='CASCADE')
    # op.drop_column('langchain_pg_embedding', 'cmetadata')
    # op.drop_column('langchain_pg_embedding', 'collection_id')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # op.add_column('langchain_pg_embedding', sa.Column('collection_id', sa.UUID(), autoincrement=False, nullable=True))
    # op.add_column('langchain_pg_embedding', sa.Column('cmetadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    # op.drop_constraint('langchain_pg_embedding_doc_id_fkey', 'langchain_pg_embedding', type_='foreignkey')
    # op.create_foreign_key('langchain_pg_embedding_collection_id_fkey', 'langchain_pg_embedding', 'langchain_pg_collection', ['collection_id'], ['uuid'], ondelete='CASCADE')
    op.alter_column('langchain_pg_embedding', 'document',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('langchain_pg_embedding', 'doc_id',
               existing_type=sa.INTEGER(),
               nullable=False)
    # op.drop_column('langchain_pg_embedding', 'encrypted')
    op.drop_column('langchain_pg_embedding', 'jmeta')
    op.drop_column('langchain_pg_embedding', 'chunk_len_in_chars')
    op.drop_column('langchain_pg_embedding', 'chunk_num')
    op.drop_column('langchain_pg_embedding', 'page')
    op.alter_column('langchain_pg_collection', 'name',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.drop_table('langchain_pg_web')
    op.drop_table('langchain_pg_document')
    # ### end Alembic commands ###
